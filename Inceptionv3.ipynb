{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrushabhmudda/Deep-Learning-project/blob/main/Inceptionv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtNrsnG5r3WA",
        "outputId": "f8106bb1-5064-4224-b603-1a32d196e258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive mounted\n",
            "‚úÖ Data files found\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# =====================================\n",
        "# MOUNT GOOGLE DRIVE\n",
        "# =====================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted\")\n",
        "\n",
        "# =====================================\n",
        "# DEFINE PATHS\n",
        "# =====================================\n",
        "DATA_PATH = '/content/drive/MyDrive/ISIC_2024_Project/data/raw/'\n",
        "ZIP_PATH = '/content/drive/MyDrive/isic-2024-challenge.zip'\n",
        "METADATA_FILE = DATA_PATH + 'train-metadata.csv'\n",
        "HDF5_PATH = DATA_PATH + 'train-image.hdf5'\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/ISIC_2024_Project/models/'\n",
        "RESULTS_PATH = '/content/drive/MyDrive/ISIC_2024_Project/results/'\n",
        "\n",
        "# =====================================\n",
        "# CHECK AND EXTRACT DATA\n",
        "# =====================================\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "# Check if metadata exists, if not extract from zip\n",
        "if not os.path.exists(METADATA_FILE):\n",
        "    print(f\"\\n‚ö†Ô∏è Metadata file not found. Extracting from {ZIP_PATH}...\")\n",
        "    if os.path.exists(ZIP_PATH):\n",
        "        with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "            extract_path = '/content/drive/MyDrive/ISIC_2024_Project/data/'\n",
        "            zip_ref.extractall(extract_path)\n",
        "            print(f\"   ‚úÖ Extraction complete to {extract_path}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"‚ùå Zip file not found at {ZIP_PATH}\")\n",
        "else:\n",
        "    print(f\"‚úÖ Data files found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# LOAD METADATA\n",
        "# =====================================\n",
        "print(\"\\nüìä Loading metadata...\")\n",
        "train_metadata = pd.read_csv(METADATA_FILE)\n",
        "print(f\"   Metadata shape: {train_metadata.shape}\")\n",
        "print(f\"   Columns: {list(train_metadata.columns)}\")\n",
        "\n",
        "# Check target distribution\n",
        "if 'target' in train_metadata.columns:\n",
        "    target_counts = train_metadata['target'].value_counts()\n",
        "    print(f\"\\n   Target distribution:\")\n",
        "    print(f\"   - Benign (0): {target_counts.get(0, 0):,}\")\n",
        "    print(f\"   - Malignant (1): {target_counts.get(1, 0):,}\")\n",
        "    if target_counts.get(1, 1) > 0:\n",
        "        print(f\"   - Imbalance ratio: 1:{target_counts.get(0, 0) // target_counts.get(1, 1)}\")\n",
        "\n",
        "# =====================================\n",
        "# CUSTOM HDF5 DATA GENERATOR\n",
        "# =====================================\n",
        "class HDF5ImageGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Memory-efficient generator that loads images from HDF5 in batches\"\"\"\n",
        "\n",
        "    def __init__(self, h5_path, image_ids, labels, batch_size=32,\n",
        "                 target_size=(299, 299), augment=False, shuffle=True):\n",
        "        self.h5_path = h5_path\n",
        "        self.image_ids = image_ids\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.augment = augment\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.image_ids))\n",
        "\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_ids) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start_idx = index * self.batch_size\n",
        "        end_idx = min((index + 1) * self.batch_size, len(self.image_ids))\n",
        "        batch_indexes = self.indexes[start_idx:end_idx]\n",
        "\n",
        "        X, y = self.__data_generation(batch_indexes)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, batch_indexes):\n",
        "        X = np.empty((len(batch_indexes), *self.target_size, 3), dtype=np.float32)\n",
        "        y = np.empty((len(batch_indexes)), dtype=np.float32)\n",
        "\n",
        "        with h5py.File(self.h5_path, 'r') as h5_file:\n",
        "            for i, idx in enumerate(batch_indexes):\n",
        "                img_id = self.image_ids[idx]\n",
        "\n",
        "                jpeg_bytes = h5_file[img_id][()]\n",
        "                img = Image.open(BytesIO(jpeg_bytes))\n",
        "                img = img.resize(self.target_size, Image.BILINEAR)\n",
        "                img_array = np.array(img, dtype=np.float32)\n",
        "\n",
        "                if len(img_array.shape) == 2:\n",
        "                    img_array = np.stack([img_array] * 3, axis=-1)\n",
        "\n",
        "                img_array = (img_array / 127.5) - 1.0\n",
        "\n",
        "                X[i,] = img_array\n",
        "                y[i] = self.labels[idx]\n",
        "\n",
        "        if self.augment:\n",
        "            X = self.__augment_batch(X)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def __augment_batch(self, images):\n",
        "        augmented = []\n",
        "        for img in images:\n",
        "            if np.random.rand() > 0.5:\n",
        "                img = np.fliplr(img)\n",
        "            if np.random.rand() > 0.5:\n",
        "                img = np.flipud(img)\n",
        "            augmented.append(img)\n",
        "        return np.array(augmented)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkfOJ_X2r8I1",
        "outputId": "b0ca6ee6-e904-461a-d0ec-43fa3aeb41c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Loading metadata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-79945172.py:5: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_metadata = pd.read_csv(METADATA_FILE)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Metadata shape: (401059, 55)\n",
            "   Columns: ['isic_id', 'target', 'patient_id', 'age_approx', 'sex', 'anatom_site_general', 'clin_size_long_diam_mm', 'image_type', 'tbp_tile_type', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB', 'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_location', 'tbp_lv_location_simple', 'tbp_lv_minorAxisMM', 'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color', 'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL', 'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle', 'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z', 'attribution', 'copyright_license', 'lesion_id', 'iddx_full', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4', 'iddx_5', 'mel_mitotic_index', 'mel_thick_mm', 'tbp_lv_dnn_lesion_confidence']\n",
            "\n",
            "   Target distribution:\n",
            "   - Benign (0): 400,666\n",
            "   - Malignant (1): 393\n",
            "   - Imbalance ratio: 1:1019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# SETUP DATA GENERATORS\n",
        "# =====================================\n",
        "print(\"\\nüîß Setting up data generators...\")\n",
        "\n",
        "train_ids = train_metadata['isic_id'].values\n",
        "train_labels = train_metadata['target'].values\n",
        "\n",
        "train_ids_split, val_ids_split, train_labels_split, val_labels_split = train_test_split(\n",
        "    train_ids, train_labels, test_size=0.2, stratify=train_labels, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"   Training samples: {len(train_ids_split):,}\")\n",
        "print(f\"   Validation samples: {len(val_ids_split):,}\")\n",
        "print(f\"   Malignant in train: {np.sum(train_labels_split):,}\")\n",
        "print(f\"   Malignant in val: {np.sum(val_labels_split):,}\")\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (299, 299)\n",
        "\n",
        "train_generator = HDF5ImageGenerator(\n",
        "    h5_path=HDF5_PATH,\n",
        "    image_ids=train_ids_split,\n",
        "    labels=train_labels_split,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMG_SIZE,\n",
        "    augment=True,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = HDF5ImageGenerator(\n",
        "    h5_path=HDF5_PATH,\n",
        "    image_ids=val_ids_split,\n",
        "    labels=val_labels_split,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMG_SIZE,\n",
        "    augment=False,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Generators ready!\")\n",
        "\n",
        "# =====================================\n",
        "# BUILD INCEPTIONV3 MODEL\n",
        "# =====================================\n",
        "print(\"\\nüèóÔ∏è Building InceptionV3 model...\")\n",
        "\n",
        "base_model = InceptionV3(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(299, 299, 3)\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "x = Dense(512, activation='relu', name='fc1')(x)\n",
        "x = Dropout(0.5, name='dropout')(x)\n",
        "predictions = Dense(1, activation='sigmoid', name='predictions')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')  # This is Sensitivity\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"   Total params: {model.count_params():,}\")\n",
        "print(\"‚úÖ Model built and compiled!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UH4-akpsCKw",
        "outputId": "355a2ac0-b930-47de-d43f-a5290eaee244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß Setting up data generators...\n",
            "   Training samples: 320,847\n",
            "   Validation samples: 80,212\n",
            "   Malignant in train: 314\n",
            "   Malignant in val: 79\n",
            "‚úÖ Generators ready!\n",
            "\n",
            "üèóÔ∏è Building InceptionV3 model...\n",
            "   Total params: 22,852,385\n",
            "‚úÖ Model built and compiled!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# CALCULATE CLASS WEIGHTS\n",
        "# =====================================\n",
        "print(\"\\n‚öñÔ∏è Calculating class weights...\")\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_labels_split),\n",
        "    y=train_labels_split\n",
        ")\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "\n",
        "print(f\"   Class 0 (Benign) weight: {class_weight_dict[0]:.4f}\")\n",
        "print(f\"   Class 1 (Malignant) weight: {class_weight_dict[1]:.4f}\")\n",
        "\n",
        "# =====================================\n",
        "# SETUP CALLBACKS\n",
        "# =====================================\n",
        "print(\"\\nüìã Setting up callbacks...\")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        MODEL_SAVE_PATH + 'inceptionv3_best.h5',\n",
        "        monitor='val_auc',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_auc',\n",
        "        mode='max',\n",
        "        patience=5,\n",
        "        verbose=1,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        verbose=1,\n",
        "        min_lr=1e-7\n",
        "    ),\n",
        "    keras.callbacks.CSVLogger(\n",
        "        RESULTS_PATH + 'training_log.csv',\n",
        "        append=False\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"‚úÖ Callbacks configured!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYV9jNPSsFaw",
        "outputId": "16e512b6-e778-4785-cc49-f157b43ee95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚öñÔ∏è Calculating class weights...\n",
            "   Class 0 (Benign) weight: 0.5005\n",
            "   Class 1 (Malignant) weight: 510.9029\n",
            "\n",
            "üìã Setting up callbacks...\n",
            "‚úÖ Callbacks configured!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# TRAIN MODEL\n",
        "# =====================================\n",
        "print(\"\\nüöÄ Starting training...\\n\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=15,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Training complete!\")\n",
        "\n",
        "# =====================================\n",
        "# SAVE FINAL MODEL TO GOOGLE DRIVE\n",
        "# =====================================\n",
        "print(\"\\nüíæ Saving model to Google Drive...\")\n",
        "model.save(MODEL_SAVE_PATH + 'inceptionv3_final.h5')\n",
        "print(f\"   ‚úÖ Model saved to {MODEL_SAVE_PATH}inceptionv3_final.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJzegcWh3iMj",
        "outputId": "915f5352-8115-4f91-8579-e97ae1bbda5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ Starting training...\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7321 - auc: 0.5372 - loss: 2.7511 - precision: 0.0013 - recall: 0.3397\n",
            "Epoch 1: val_auc improved from -inf to 0.77520, saving model to /content/drive/MyDrive/ISIC_2024_Project/models/inceptionv3_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1863s\u001b[0m 184ms/step - accuracy: 0.7321 - auc: 0.5372 - loss: 2.7510 - precision: 0.0013 - recall: 0.3397 - val_accuracy: 0.0234 - val_auc: 0.7752 - val_loss: 1.4627 - val_precision: 0.0010 - val_recall: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 2/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.4940 - auc: 0.6460 - loss: 0.9011 - precision: 0.0014 - recall: 0.6748\n",
            "Epoch 2: val_auc did not improve from 0.77520\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1826s\u001b[0m 182ms/step - accuracy: 0.4940 - auc: 0.6460 - loss: 0.9012 - precision: 0.0014 - recall: 0.6748 - val_accuracy: 0.6631 - val_auc: 0.7717 - val_loss: 0.8973 - val_precision: 0.0023 - val_recall: 0.7848 - learning_rate: 0.0010\n",
            "Epoch 3/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.5823 - auc: 0.6842 - loss: 1.0577 - precision: 0.0017 - recall: 0.6783\n",
            "Epoch 3: val_auc did not improve from 0.77520\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1802s\u001b[0m 180ms/step - accuracy: 0.5823 - auc: 0.6842 - loss: 1.0577 - precision: 0.0017 - recall: 0.6783 - val_accuracy: 0.3254 - val_auc: 0.7329 - val_loss: 0.7678 - val_precision: 0.0012 - val_recall: 0.8354 - learning_rate: 0.0010\n",
            "Epoch 4/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.5355 - auc: 0.6769 - loss: 0.7760 - precision: 0.0015 - recall: 0.6757\n",
            "Epoch 4: val_auc did not improve from 0.77520\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1831s\u001b[0m 183ms/step - accuracy: 0.5355 - auc: 0.6769 - loss: 0.7760 - precision: 0.0015 - recall: 0.6757 - val_accuracy: 0.9989 - val_auc: 0.5846 - val_loss: 0.0469 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 5/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6035 - auc: 0.6548 - loss: 1.1498 - precision: 0.0015 - recall: 0.6376\n",
            "Epoch 5: val_auc did not improve from 0.77520\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1822s\u001b[0m 182ms/step - accuracy: 0.6035 - auc: 0.6548 - loss: 1.1497 - precision: 0.0015 - recall: 0.6376 - val_accuracy: 0.7210 - val_auc: 0.7725 - val_loss: 0.5254 - val_precision: 0.0025 - val_recall: 0.6962 - learning_rate: 0.0010\n",
            "Epoch 6/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.6512 - auc: 0.7516 - loss: 0.7189 - precision: 0.0022 - recall: 0.7104\n",
            "Epoch 6: val_auc improved from 0.77520 to 0.79946, saving model to /content/drive/MyDrive/ISIC_2024_Project/models/inceptionv3_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1815s\u001b[0m 181ms/step - accuracy: 0.6512 - auc: 0.7516 - loss: 0.7189 - precision: 0.0022 - recall: 0.7104 - val_accuracy: 0.8436 - val_auc: 0.7995 - val_loss: 0.3705 - val_precision: 0.0037 - val_recall: 0.5949 - learning_rate: 0.0010\n",
            "Epoch 7/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7247 - auc: 0.7630 - loss: 0.6388 - precision: 0.0022 - recall: 0.6573\n",
            "Epoch 7: val_auc did not improve from 0.79946\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1832s\u001b[0m 183ms/step - accuracy: 0.7247 - auc: 0.7630 - loss: 0.6389 - precision: 0.0022 - recall: 0.6573 - val_accuracy: 0.8828 - val_auc: 0.7875 - val_loss: 0.3655 - val_precision: 0.0049 - val_recall: 0.5823 - learning_rate: 5.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.6338 - auc: 0.7445 - loss: 0.6750 - precision: 0.0022 - recall: 0.7579\n",
            "Epoch 8: val_auc did not improve from 0.79946\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1779s\u001b[0m 177ms/step - accuracy: 0.6338 - auc: 0.7445 - loss: 0.6750 - precision: 0.0022 - recall: 0.7579 - val_accuracy: 0.8998 - val_auc: 0.7896 - val_loss: 0.2549 - val_precision: 0.0047 - val_recall: 0.4810 - learning_rate: 5.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7242 - auc: 0.7609 - loss: 0.6019 - precision: 0.0022 - recall: 0.6348\n",
            "Epoch 9: val_auc did not improve from 0.79946\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1710s\u001b[0m 171ms/step - accuracy: 0.7242 - auc: 0.7609 - loss: 0.6019 - precision: 0.0022 - recall: 0.6348 - val_accuracy: 0.7622 - val_auc: 0.7914 - val_loss: 0.4494 - val_precision: 0.0027 - val_recall: 0.6582 - learning_rate: 2.5000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7239 - auc: 0.7950 - loss: 0.5878 - precision: 0.0027 - recall: 0.7245\n",
            "Epoch 10: val_auc did not improve from 0.79946\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1810s\u001b[0m 181ms/step - accuracy: 0.7239 - auc: 0.7950 - loss: 0.5878 - precision: 0.0027 - recall: 0.7245 - val_accuracy: 0.8414 - val_auc: 0.7827 - val_loss: 0.3783 - val_precision: 0.0038 - val_recall: 0.6076 - learning_rate: 2.5000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7429 - auc: 0.7477 - loss: 0.6064 - precision: 0.0022 - recall: 0.6148\n",
            "Epoch 11: val_auc did not improve from 0.79946\n",
            "\u001b[1m10027/10027\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1749s\u001b[0m 174ms/step - accuracy: 0.7429 - auc: 0.7477 - loss: 0.6064 - precision: 0.0022 - recall: 0.6148 - val_accuracy: 0.8015 - val_auc: 0.7896 - val_loss: 0.4186 - val_precision: 0.0030 - val_recall: 0.6076 - learning_rate: 1.2500e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Training complete!\n",
            "\n",
            "üíæ Saving model to Google Drive...\n",
            "   ‚úÖ Model saved to /content/drive/MyDrive/ISIC_2024_Project/models/inceptionv3_final.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# EVALUATION ON VALIDATION SET\n",
        "# =====================================\n",
        "print(\"\\nüìä Evaluating model on validation set...\")\n",
        "\n",
        "# Get predictions\n",
        "y_pred_probs = model.predict(val_generator, verbose=1)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true = val_labels_split\n",
        "\n",
        "# Calculate metrics\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)  # This is SENSITIVITY\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "roc_auc = roc_auc_score(y_true, y_pred_probs)\n",
        "\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"\\nüìà EVALUATION METRICS:\")\n",
        "print(f\"   Accuracy: {accuracy:.4f}\")\n",
        "print(f\"   Sensitivity (Recall): {recall:.4f}\")\n",
        "print(f\"   Specificity: {specificity:.4f}\")\n",
        "print(f\"   Precision: {precision:.4f}\")\n",
        "print(f\"   F1 Score: {f1:.4f}\")\n",
        "print(f\"   AUC-ROC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save metrics to CSV\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Sensitivity (Recall)', 'Specificity', 'Precision', 'F1 Score', 'AUC-ROC'],\n",
        "    'Value': [accuracy, recall, specificity, precision, f1, roc_auc]\n",
        "})\n",
        "metrics_df.to_csv(RESULTS_PATH + 'evaluation_metrics.csv', index=False)\n",
        "print(f\"\\n‚úÖ Metrics saved to {RESULTS_PATH}evaluation_metrics.csv\")\n",
        "\n",
        "# =====================================\n",
        "# PLOT AND SAVE CONFUSION MATRIX\n",
        "# =====================================\n",
        "print(\"\\nüìä Generating confusion matrix...\")\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=['Benign', 'Malignant'],\n",
        "            yticklabels=['Benign', 'Malignant'])\n",
        "plt.title('Confusion Matrix - InceptionV3', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig(RESULTS_PATH + 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"   ‚úÖ Confusion matrix saved to {RESULTS_PATH}confusion_matrix.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1kFXNw0bIJz",
        "outputId": "e561c6cf-146f-4c0a-f533-f2988dd07e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Evaluating model on validation set...\n",
            "\u001b[1m2507/2507\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 129ms/step\n",
            "\n",
            "üìà EVALUATION METRICS:\n",
            "   Accuracy: 0.8436\n",
            "   Sensitivity (Recall): 0.5949\n",
            "   Specificity: 0.8438\n",
            "   Precision: 0.0037\n",
            "   F1 Score: 0.0074\n",
            "   AUC-ROC: 0.7996\n",
            "\n",
            "‚úÖ Metrics saved to /content/drive/MyDrive/ISIC_2024_Project/results/evaluation_metrics.csv\n",
            "\n",
            "üìä Generating confusion matrix...\n",
            "   ‚úÖ Confusion matrix saved to /content/drive/MyDrive/ISIC_2024_Project/results/confusion_matrix.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# PLOT AND SAVE ROC CURVE\n",
        "# =====================================\n",
        "print(\"\\nüìà Generating ROC curve...\")\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)\n",
        "roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc_value:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
        "plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
        "plt.title('ROC Curve - InceptionV3', fontsize=16, fontweight='bold')\n",
        "plt.legend(loc='lower right', fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(RESULTS_PATH + 'roc_curve.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"   ‚úÖ ROC curve saved to {RESULTS_PATH}roc_curve.png\")\n",
        "plt.close()\n",
        "\n",
        "# =====================================\n",
        "# PLOT AND SAVE TRAINING HISTORY\n",
        "# =====================================\n",
        "print(\"\\nüìâ Generating training history plots...\")\n",
        "\n",
        "# Plot 1: Loss curves\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Loss\n",
        "axes[0, 0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "axes[0, 0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "axes[0, 0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Epoch', fontsize=11)\n",
        "axes[0, 0].set_ylabel('Loss', fontsize=11)\n",
        "axes[0, 0].legend(fontsize=10)\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Accuracy\n",
        "axes[0, 1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "axes[0, 1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "axes[0, 1].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Epoch', fontsize=11)\n",
        "axes[0, 1].set_ylabel('Accuracy', fontsize=11)\n",
        "axes[0, 1].legend(fontsize=10)\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# AUC\n",
        "axes[1, 0].plot(history.history['auc'], label='Training AUC', linewidth=2)\n",
        "axes[1, 0].plot(history.history['val_auc'], label='Validation AUC', linewidth=2)\n",
        "axes[1, 0].set_title('Model AUC', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Epoch', fontsize=11)\n",
        "axes[1, 0].set_ylabel('AUC', fontsize=11)\n",
        "axes[1, 0].legend(fontsize=10)\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Recall (Sensitivity)\n",
        "axes[1, 1].plot(history.history['recall'], label='Training Recall', linewidth=2)\n",
        "axes[1, 1].plot(history.history['val_recall'], label='Validation Recall', linewidth=2)\n",
        "axes[1, 1].set_title('Model Recall (Sensitivity)', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Epoch', fontsize=11)\n",
        "axes[1, 1].set_ylabel('Recall', fontsize=11)\n",
        "axes[1, 1].legend(fontsize=10)\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(RESULTS_PATH + 'training_history.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"   ‚úÖ Training history saved to {RESULTS_PATH}training_history.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zRpZ35Hibuk",
        "outputId": "1e41ef2c-ec3d-40a9-f902-659d4055ae27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìà Generating ROC curve...\n",
            "   ‚úÖ ROC curve saved to /content/drive/MyDrive/ISIC_2024_Project/results/roc_curve.png\n",
            "\n",
            "üìâ Generating training history plots...\n",
            "   ‚úÖ Training history saved to /content/drive/MyDrive/ISIC_2024_Project/results/training_history.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# SAVE DETAILED CLASSIFICATION REPORT\n",
        "# =====================================\n",
        "print(\"\\nüìÑ Generating classification report...\")\n",
        "\n",
        "report = classification_report(y_true, y_pred,\n",
        "                               target_names=['Benign', 'Malignant'],\n",
        "                               output_dict=True)\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "report_df.to_csv(RESULTS_PATH + 'classification_report.csv')\n",
        "print(f\"   ‚úÖ Classification report saved to {RESULTS_PATH}classification_report.csv\")\n",
        "\n",
        "# =====================================\n",
        "# FINAL SUMMARY\n",
        "# =====================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä FINAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n‚úÖ Model saved to: {MODEL_SAVE_PATH}\")\n",
        "print(f\"‚úÖ All evaluation metrics and plots saved to: {RESULTS_PATH}\")\n",
        "print(\"\\nFiles saved:\")\n",
        "print(f\"   1. inceptionv3_best.h5 (best model during training)\")\n",
        "print(f\"   2. inceptionv3_final.h5 (final model)\")\n",
        "print(f\"   3. evaluation_metrics.csv\")\n",
        "print(f\"   4. confusion_matrix.png\")\n",
        "print(f\"   5. roc_curve.png\")\n",
        "print(f\"   6. training_history.png\")\n",
        "print(f\"   7. training_log.csv\")\n",
        "print(f\"   8. classification_report.csv\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nüéâ All done! Ready for presentation.\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_hldRt0itBp",
        "outputId": "21266833-7a6a-41fc-d2ed-227ae39c69b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÑ Generating classification report...\n",
            "   ‚úÖ Classification report saved to /content/drive/MyDrive/ISIC_2024_Project/results/classification_report.csv\n",
            "\n",
            "============================================================\n",
            "üìä FINAL SUMMARY\n",
            "============================================================\n",
            "\n",
            "‚úÖ Model saved to: /content/drive/MyDrive/ISIC_2024_Project/models/\n",
            "‚úÖ All evaluation metrics and plots saved to: /content/drive/MyDrive/ISIC_2024_Project/results/\n",
            "\n",
            "Files saved:\n",
            "   1. inceptionv3_best.h5 (best model during training)\n",
            "   2. inceptionv3_final.h5 (final model)\n",
            "   3. evaluation_metrics.csv\n",
            "   4. confusion_matrix.png\n",
            "   5. roc_curve.png\n",
            "   6. training_history.png\n",
            "   7. training_log.csv\n",
            "   8. classification_report.csv\n",
            "\n",
            "============================================================\n",
            "\n",
            "üéâ All done! Ready for presentation.\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}